{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>939</td><td>application_1551670200070_0557</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://data-services3.cs.rutgers.edu:8088/proxy/application_1551670200070_0557/\">Link</a></td><td><a target=\"_blank\" href=\"http://data2.cs.rutgers.edu:8042/node/containerlogs/container_e68_1551670200070_0557_01_000001/hz333\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def getLine(row):\n",
    "\tindex, name, tags = row\n",
    "\ttags = tags.split('|')\n",
    "\treturn (index, tags)\n",
    "\n",
    "def getTag(line):\n",
    "\tindex, tags = line\n",
    "\treturn [(tag, 1) for tag in tags] \n",
    "\n",
    "def count(x, y):\n",
    "\treturn x + y\n",
    "\n",
    "class IDFScore(object):\n",
    "\tdef __init__(self, tagCount):\n",
    "\t\tself.tagCount = dict(tagCount)\n",
    "\t\tself.N = sum(self.tagCount.values())\n",
    "\t\tself.tagList = sorted(self.tagCount.keys()) #the col index\n",
    "\n",
    "\tdef get(self, line):\n",
    "\t\tindex, tags = line\n",
    "\t\ttags = frozenset(tags)\n",
    "\t\tindexIdf = [index]\n",
    "\t\tfor tag in self.tagList:\n",
    "\t\t\tif tag in tags:\n",
    "\t\t\t\tindexIdf.append(math.log(self.N / self.tagCount[tag], 2))\n",
    "\t\t\telse:\n",
    "\t\t\t\tindexIdf.append(0.)\n",
    "\t\treturn indexIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('/user/hz333/data/project/movies.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(idx, name, tags) => (idx, [tag])\n",
    "line = data.rdd.map(getLine)\n",
    "\n",
    "#(idx, [tag]) => [(tag, 1)]\n",
    "tags = line.flatMap(getTag)\n",
    "#(tag,1) => (tag, count)\n",
    "tagCount = tags.reduceByKey(count)\n",
    "tagCount = tagCount.collect()\n",
    "\n",
    "IDF = IDFScore(tagCount)\n",
    "\n",
    "#(idx, [tag]) => (idx, tagIDFs)\n",
    "movieIDF = line.map(IDF.get) #the same tag appears in a movie no more than once => IDF = TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 0.0, 0.0, 4.128074962004387, 5.17568531597321, 5.055674454445015, 2.5557325381381646, 0.0, 0.0, 0.0, 4.82523436773027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]"
     ]
    }
   ],
   "source": [
    "movieIDF.filter(lambda x: x[0] == '1').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieIDFCSV = spark.createDataFrame(movieIDF, samplingRatio = 1)\n",
    "movieIDFCSV.write.option('header', 'false').csv('/user/hz333/data/project/mMetaProfi.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
